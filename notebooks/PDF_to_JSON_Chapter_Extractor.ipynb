{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Guide to Add Book Summaries"
      ],
      "metadata": {
        "id": "LNVkg0ulMV9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Input form for ISBN and processing flags.\n",
        "#@markdown Fill in the ISBN of the PDF and select options for processing.\n",
        "\n",
        "isbn_ten = \"9354990517\" #@param {type:\"string\"}\n",
        "exclude_fluff = True #@param {type:\"boolean\"}\n",
        "remove_empty_chapters = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---"
      ],
      "metadata": {
        "id": "lvl4Z7jw52zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code below processes the uploaded PDF according to the provided ISBN and flags.\n",
        "# It extracts the chapters and generates a JSON file with the chapter contents.\n",
        "import re\n",
        "import os\n",
        "import copy\n",
        "import json\n",
        "import pprint\n",
        "import logging\n",
        "from typing import Dict, Union\n",
        "from pypdf import PdfReader\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')\n",
        "\n",
        "\n",
        "def bookmark_dict(\n",
        "    bookmark_list, reader: PdfReader, use_labels: bool = False,\n",
        ") -> Dict[Union[str, int], str]:\n",
        "    \"\"\"\n",
        "    Extract all bookmarks as a flat dictionary.\n",
        "\n",
        "    Args:\n",
        "        bookmark_list: The reader. outline or a recursive call\n",
        "        use_labels: If true, use page labels. If False, use page indices.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary mapping page labels (or page indices) to their title\n",
        "\n",
        "    Examples:\n",
        "        Download the PDF from https://zenodo.org/record/50395 to give it a try\n",
        "    \"\"\"\n",
        "    result = {}\n",
        "    for item in bookmark_list:\n",
        "        if isinstance(item, list):\n",
        "            # recursive call\n",
        "            result.update(bookmark_dict(item, reader))\n",
        "        else:\n",
        "            page_index = reader.get_destination_page_number(item)\n",
        "            page_label = reader.page_labels[page_index]\n",
        "            if use_labels:\n",
        "                result[page_label] = item.title\n",
        "            else:\n",
        "                result[page_index] = item.title\n",
        "    return result\n",
        "\n",
        "\n",
        "def array_to_json_file(array, file_name):\n",
        "    \"\"\"\n",
        "    Saves a list of dictionaries to a JSON file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_name, 'w', encoding='utf-8') as json_file:\n",
        "            json.dump(array, json_file, ensure_ascii=False, indent=4)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving JSON: {e}\")\n",
        "\n",
        "\n",
        "def construct_page_splits_array(reader, bms):\n",
        "    last_page = len(reader.pages)\n",
        "    split_at_list = list(bms.keys())\n",
        "    split_at_list.append(last_page)\n",
        "    return split_at_list\n",
        "\n",
        "\n",
        "def construct_start_and_end_arrays(split_at_pages):\n",
        "    start = 0\n",
        "    end = 0\n",
        "    splits = []\n",
        "    for i in range(len(split_at_pages)):\n",
        "        if i == 0:\n",
        "            start = 1\n",
        "            end = split_at_pages[i]\n",
        "        else:\n",
        "            start = split_at_pages[i - 1]\n",
        "            end = split_at_pages[i]\n",
        "        print(f\"Start: {start}, End: {end}\")\n",
        "        splits.append((start, end))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def get_chapter(split, reader, bms):\n",
        "    content = []\n",
        "    # print(split)\n",
        "    start, end = split\n",
        "    # print(start, end)\n",
        "    t = type(start)\n",
        "    name = bms.get(start, '')\n",
        "    print(f'Search for {start} as type {t} and found {name}')\n",
        "\n",
        "    for page_nb in range(int(start), int(end)):\n",
        "        page_text = reader.pages[page_nb].extract_text()\n",
        "        content.append(page_text)\n",
        "    chapter_content = ''.join(content)\n",
        "    return {\n",
        "        'name': name,\n",
        "        'contents': chapter_content,\n",
        "        'type_of_name': t.__name__  # keep .__name__ this here\n",
        "    }\n",
        "\n",
        "\n",
        "def count_words(text):\n",
        "    \"\"\"\n",
        "    Counts the number of words in the given text using a regular expression that matches word boundaries.\n",
        "\n",
        "    Args:\n",
        "        text (str): The text string to count words in.\n",
        "\n",
        "    Returns:\n",
        "        int: The number of words in the text.\n",
        "    \"\"\"\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    return len(words)\n",
        "\n",
        "\n",
        "def extract_pdf_chapters(pdf_file_path):\n",
        "\n",
        "    reader = PdfReader(pdf_file_path)\n",
        "    bms = bookmark_dict(reader.outline, reader, use_labels=True)\n",
        "    print(bms.keys())\n",
        "    print(bms.values())\n",
        "\n",
        "    for page_nb, title in sorted(bms.items(), key=lambda n: f\"{str(n[0]):>5}\"):\n",
        "        print(f\"{page_nb:>3}: {title}\")\n",
        "        pass\n",
        "\n",
        "    sequence = construct_page_splits_array(reader, bms)\n",
        "    splits = construct_start_and_end_arrays(sequence)\n",
        "    splits_excluding_first = splits[1:]\n",
        "\n",
        "    chapters = []\n",
        "    for index, split in enumerate(splits_excluding_first):\n",
        "        chapter = get_chapter(split, reader, bms)\n",
        "        chapter['sequence_index'] = index\n",
        "        chapter['part'] = ''\n",
        "        chapters.append(chapter)\n",
        "\n",
        "    return chapters\n",
        "\n",
        "\n",
        "def exclude_fluff_from_request_bodies(json_data):\n",
        "        \"\"\"\n",
        "        request_bodies = {\n",
        "                    \"isbn_ten\": isbn_ten,\n",
        "                    \"name\": chapter_name,\n",
        "                    \"sequence_index\": index,\n",
        "                    \"contents\": contents,\n",
        "                    \"part\": chapter_part,\n",
        "                }\n",
        "        \"\"\"\n",
        "        # given a list of request bodies, exclude the ones that are too small or have keywords\n",
        "        exclude_keywords = [\n",
        "            \"acknowledgement\",\n",
        "            \"acknowledgment\",\n",
        "            \"reference\",\n",
        "            \"appendix\",\n",
        "            \"bibliography\",\n",
        "            \"glossary\",\n",
        "            \"copyright\",\n",
        "            \"author's note\",\n",
        "            \"note on\",\n",
        "            \"publisher's note\",\n",
        "            \"about the author\",\n",
        "            \"list of collaborators\",\n",
        "            \"notes\",\n",
        "            \"praise for\",\n",
        "            \"praise\",\n",
        "            \"thanks\",\n",
        "            \"cover\",\n",
        "            \"index\",\n",
        "            \"resources\",\n",
        "            \"sources\",\n",
        "            \"table of contents\",\n",
        "            \"title page\",\n",
        "            \"penguin books\",\n",
        "            \"further readings\",\n",
        "            \"illustration credits\",\n",
        "            \"photo insert\",\n",
        "            \"about the publisher\",\n",
        "            \"author\"\n",
        "        ]\n",
        "        exclude_indices = []\n",
        "\n",
        "        for index, request_body in enumerate(json_data):\n",
        "            try:\n",
        "                chapter_contents = request_body[\"contents\"]\n",
        "                chapter_name = request_body[\"name\"].lower()\n",
        "\n",
        "                # Log if chapter should not be filtered\n",
        "                if \"chapter\" in chapter_name:\n",
        "                    print(f\"CHAPTER DOES NOT NEED TO BE FILTERED: {request_body['name']}\")\n",
        "                    continue\n",
        "\n",
        "                # Exclude chapters with exclusionary keywords\n",
        "                if any(keyword in chapter_name for keyword in exclude_keywords):\n",
        "                    exclude_indices.append(index)\n",
        "                    print(f\"\\tEXCLUDED CHAPTER - KEYWORDS FLUFF: {request_body['name']}\")\n",
        "                    continue\n",
        "\n",
        "                # Exclude if chapters not big enough\n",
        "                if count_words(chapter_contents) < 1000:\n",
        "                    exclude_indices.append(index)\n",
        "                    print(\n",
        "                        f\"\\tEXCLUDED CHAPTER - TOO SMALL: {request_body['name']} ({count_words(chapter_contents)} words)\")\n",
        "                else:\n",
        "                    print(f\"CHAPTER DOES NOT NEED TO BE FILTERED: {request_body['name']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during chapter fluff filtering {request_body['name']}: {str(e)}\")\n",
        "\n",
        "        included_request_bodies = [\n",
        "            request_body for index, request_body in enumerate(json_data)\n",
        "            if index not in exclude_indices\n",
        "        ]\n",
        "        try:\n",
        "            print(\"\\nCHAPTERS INCLUDED:\")\n",
        "            for request_body in included_request_bodies:\n",
        "                try:\n",
        "                    print(request_body[\"name\"])\n",
        "                except KeyError:\n",
        "                    print(\"Error: 'name' key is missing in some request bodies.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during the fluff filtering process: {str(e)}\")\n",
        "\n",
        "        # Using deepcopy to create a complete copy of the data, excluding unwanted elements\n",
        "        filtered_request_bodies = copy.deepcopy(\n",
        "            [request_body for index, request_body in enumerate(json_data) if index not in exclude_indices])\n",
        "\n",
        "        return filtered_request_bodies\n",
        "\n",
        "\n",
        "def analyze_raw_extraction(data):\n",
        "    chapter_count = len(data)\n",
        "    total_word_count = 0\n",
        "\n",
        "    for index, chapter in enumerate(data):\n",
        "        words = count_words(chapter['contents'])\n",
        "        print(f\"{chapter['name']} has {words} words\")\n",
        "        total_word_count += words\n",
        "\n",
        "    filtered_data = exclude_fluff_from_request_bodies(data)\n",
        "    number_of_excluded_chapters = chapter_count - len(filtered_data)\n",
        "\n",
        "    filtered_total_word_count = 0\n",
        "    filtered_chapters_with_count = ''\n",
        "    for index, chapter in enumerate(filtered_data):\n",
        "        words = count_words(chapter['contents'])\n",
        "        # print(f\"{chapter['name']} has {words} words\")\n",
        "        filtered_total_word_count += words\n",
        "        filtered_chapters_with_count += f\"{chapter['name']} -- {words} words\\n\"\n",
        "\n",
        "    return {\n",
        "        'chapter_count': chapter_count,\n",
        "        'total_word_count': total_word_count,\n",
        "        \"number_of_excluded_chapters\": number_of_excluded_chapters,\n",
        "        \"filtered_chapter_count\": len(filtered_data),\n",
        "        \"filtered_total_word_count\": filtered_total_word_count,\n",
        "        \"filtered_chapters_with_count\": filtered_chapters_with_count\n",
        "    }\n",
        "\n",
        "\n",
        "def propagate_name_to_part(arr):\n",
        "    propagate_name = None\n",
        "    for i, obj in enumerate(arr):\n",
        "        # If contents are blank and no name is currently being propagated, start propagation\n",
        "        if obj[\"contents\"] == \"\" and propagate_name is None:\n",
        "            propagate_name = obj[\"name\"]\n",
        "        # If contents are blank and a name is being propagated, stop propagation before updating this object\n",
        "        elif obj[\"contents\"] == \"\" and propagate_name is not None:\n",
        "            propagate_name = obj[\"name\"]  # We've encountered another empty \"contents\", reset the name\n",
        "        # Propagate the name to the part key if needed\n",
        "        elif propagate_name is not None and obj[\"type_of_name\"] == \"int\":\n",
        "            arr[i][\"part\"] = propagate_name\n",
        "    return arr\n",
        "\n",
        "\n",
        "def remove_empty_chapters(arr):\n",
        "    return [obj for obj in arr if obj[\"contents\"] != \"\"]\n",
        "\n",
        "\n",
        "def re_sequence_chapters(arr):\n",
        "    for i, obj in enumerate(arr):\n",
        "        arr[i][\"sequence_index\"] = i\n",
        "    return arr\n",
        "\n",
        "\n",
        "def inject_isbn_to_chapters(arr, isbn_ten):\n",
        "    for i, obj in enumerate(arr):\n",
        "        arr[i][\"isbn\"] = isbn_ten\n",
        "    return arr\n",
        "\n",
        "\n",
        "def remove_type_of_name_helper(arr):\n",
        "    for i, obj in enumerate(arr):\n",
        "        arr[i].pop(\"type_of_name\", None)\n",
        "    return arr\n",
        "\n",
        "\n",
        "def process_pdf(pdf_file_name, exclude_fluff=True, remove_empty_chapters=True):\n",
        "    \"\"\"\n",
        "    Main function to process the uploaded PDF file in Colab, extract chapters based on bookmarks,\n",
        "    and return a list of chapters data after applying various transformations.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        book_name = os.path.splitext(pdf_file_name)[0]  # Extract book name without .pdf\n",
        "        logging.info(f\"Processing PDF: {pdf_file_name}\")\n",
        "\n",
        "        chapters = extract_pdf_chapters(pdf_file_name)\n",
        "\n",
        "        if exclude_fluff:\n",
        "            chapters = exclude_fluff_from_request_bodies(chapters)\n",
        "        chapters_with_part_info = propagate_name_to_part(chapters)\n",
        "\n",
        "        if remove_empty_chapters:\n",
        "            chapters_without_empty = remove_empty_chapters(chapters_with_part_info)\n",
        "        else:\n",
        "            chapters_without_empty = chapters_with_part_info\n",
        "\n",
        "        chapters_resequenced = re_sequence_chapters(chapters_without_empty)\n",
        "        chapters_with_isbn = inject_isbn_to_chapters(chapters_resequenced, book_name)\n",
        "        chapters_without_type_of_name = remove_type_of_name_helper(chapters_with_isbn)\n",
        "\n",
        "        results = analyze_raw_extraction(chapters)\n",
        "        pprint.pprint(results)\n",
        "\n",
        "        return chapters_without_type_of_name\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing {pdf_file_name}: {e}\")\n",
        "        raise\n",
        "\n"
      ],
      "metadata": {
        "id": "XA7C5Bq3iz7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your PDF file here. Click the \"Choose Files\" button and select the PDF from your device.\n",
        "\n",
        "print(\"Please upload your PDF file.\")\n",
        "uploaded = files.upload()\n",
        "pdf_file_name = list(uploaded.keys())[0] # It is assumed that only one file is uploaded."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "9Flacw2PEYvF",
        "outputId": "a00703ca-b5c7-4576-b8fa-faed31a049ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PDF file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a9b0c24-c11f-4892-ad3c-af226ca8b3ca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a9b0c24-c11f-4892-ad3c-af226ca8b3ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 9354990517.pdf to 9354990517 (3).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF Processing and Chapters Data Generation\n",
        "try:\n",
        "    chapters_data = process_pdf(pdf_file_name, exclude_fluff, remove_empty_chapters)\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error processing PDF: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47l4M9kXFhBb",
        "outputId": "5d2f48cc-1c53-4270-e8e0-d15d0c999cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['3', '5', '9', '12', '15', '20', '22', '25', '29', '33', '39', '41', '42', '46', '51', '55', '56', '59', '60', '63', '65', '71', '72', '73', '76', '80', '87'])\n",
            "dict_values(['PREMIER CHAPITRE', 'CHAPITRE II', 'CHAPITRE III', 'CHAPITRE IV', 'CHAPITRE V', 'CHAPITRE VI', 'CHAPITRE VII', 'CHAPITRE VIII', 'CHAPITRE IX', 'CHAPITRE X', 'CHAPITRE XI', 'CHAPITRE XII', 'CHAPITRE XIII', 'CHAPITRE XIV', 'CHAPITRE XV', 'CHAPITRE XVI', 'CHAPITRE XVII', 'CHAPITRE XVIII', 'CHAPITRE XIX', 'CHAPITRE XX', 'CHAPITRE XXI', 'CHAPITRE XXII', 'CHAPITRE XXIII', 'CHAPITRE XXIV', 'CHAPITRE XXV', 'CHAPITRE XXVI', 'CHAPITRE XXVII'])\n",
            "  3: PREMIER CHAPITRE\n",
            "  5: CHAPITRE II\n",
            "  9: CHAPITRE III\n",
            " 12: CHAPITRE IV\n",
            " 15: CHAPITRE V\n",
            " 20: CHAPITRE VI\n",
            " 22: CHAPITRE VII\n",
            " 25: CHAPITRE VIII\n",
            " 29: CHAPITRE IX\n",
            " 33: CHAPITRE X\n",
            " 39: CHAPITRE XI\n",
            " 41: CHAPITRE XII\n",
            " 42: CHAPITRE XIII\n",
            " 46: CHAPITRE XIV\n",
            " 51: CHAPITRE XV\n",
            " 55: CHAPITRE XVI\n",
            " 56: CHAPITRE XVII\n",
            " 59: CHAPITRE XVIII\n",
            " 60: CHAPITRE XIX\n",
            " 63: CHAPITRE XX\n",
            " 65: CHAPITRE XXI\n",
            " 71: CHAPITRE XXII\n",
            " 72: CHAPITRE XXIII\n",
            " 73: CHAPITRE XXIV\n",
            " 76: CHAPITRE XXV\n",
            " 80: CHAPITRE XXVI\n",
            " 87: CHAPITRE XXVII\n",
            "Start: 1, End: 3\n",
            "Start: 3, End: 5\n",
            "Start: 5, End: 9\n",
            "Start: 9, End: 12\n",
            "Start: 12, End: 15\n",
            "Start: 15, End: 20\n",
            "Start: 20, End: 22\n",
            "Start: 22, End: 25\n",
            "Start: 25, End: 29\n",
            "Start: 29, End: 33\n",
            "Start: 33, End: 39\n",
            "Start: 39, End: 41\n",
            "Start: 41, End: 42\n",
            "Start: 42, End: 46\n",
            "Start: 46, End: 51\n",
            "Start: 51, End: 55\n",
            "Start: 55, End: 56\n",
            "Start: 56, End: 59\n",
            "Start: 59, End: 60\n",
            "Start: 60, End: 63\n",
            "Start: 63, End: 65\n",
            "Start: 65, End: 71\n",
            "Start: 71, End: 72\n",
            "Start: 72, End: 73\n",
            "Start: 73, End: 76\n",
            "Start: 76, End: 80\n",
            "Start: 80, End: 87\n",
            "Start: 87, End: 88\n",
            "Search for 3 as type <class 'str'> and found PREMIER CHAPITRE\n",
            "Search for 5 as type <class 'str'> and found CHAPITRE II\n",
            "Search for 9 as type <class 'str'> and found CHAPITRE III\n",
            "Search for 12 as type <class 'str'> and found CHAPITRE IV\n",
            "Search for 15 as type <class 'str'> and found CHAPITRE V\n",
            "Search for 20 as type <class 'str'> and found CHAPITRE VI\n",
            "Search for 22 as type <class 'str'> and found CHAPITRE VII\n",
            "Search for 25 as type <class 'str'> and found CHAPITRE VIII\n",
            "Search for 29 as type <class 'str'> and found CHAPITRE IX\n",
            "Search for 33 as type <class 'str'> and found CHAPITRE X\n",
            "Search for 39 as type <class 'str'> and found CHAPITRE XI\n",
            "Search for 41 as type <class 'str'> and found CHAPITRE XII\n",
            "Search for 42 as type <class 'str'> and found CHAPITRE XIII\n",
            "Search for 46 as type <class 'str'> and found CHAPITRE XIV\n",
            "Search for 51 as type <class 'str'> and found CHAPITRE XV\n",
            "Search for 55 as type <class 'str'> and found CHAPITRE XVI\n",
            "Search for 56 as type <class 'str'> and found CHAPITRE XVII\n",
            "Search for 59 as type <class 'str'> and found CHAPITRE XVIII\n",
            "Search for 60 as type <class 'str'> and found CHAPITRE XIX\n",
            "Search for 63 as type <class 'str'> and found CHAPITRE XX\n",
            "Search for 65 as type <class 'str'> and found CHAPITRE XXI\n",
            "Search for 71 as type <class 'str'> and found CHAPITRE XXII\n",
            "Search for 72 as type <class 'str'> and found CHAPITRE XXIII\n",
            "Search for 73 as type <class 'str'> and found CHAPITRE XXIV\n",
            "Search for 76 as type <class 'str'> and found CHAPITRE XXV\n",
            "Search for 80 as type <class 'str'> and found CHAPITRE XXVI\n",
            "Search for 87 as type <class 'str'> and found CHAPITRE XXVII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: PREMIER CHAPITRE\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE II\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE III\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE IV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE V\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE VI (974 words)\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE VII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE VIII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE IX\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE X\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XI\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XII (742 words)\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XIII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XIV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XV\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XVI (941 words)\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XVII\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XVIII (294 words)\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XIX (817 words)\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XX (755 words)\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXI\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XXII (426 words)\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XXIII (905 words)\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXIV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXVI\n",
            "\tEXCLUDED CHAPTER - TOO SMALL: CHAPITRE XXVII (587 words)\n",
            "\n",
            "CHAPTERS INCLUDED:\n",
            "PREMIER CHAPITRE\n",
            "CHAPITRE II\n",
            "CHAPITRE III\n",
            "CHAPITRE IV\n",
            "CHAPITRE V\n",
            "CHAPITRE VII\n",
            "CHAPITRE VIII\n",
            "CHAPITRE IX\n",
            "CHAPITRE X\n",
            "CHAPITRE XI\n",
            "CHAPITRE XIII\n",
            "CHAPITRE XIV\n",
            "CHAPITRE XV\n",
            "CHAPITRE XVII\n",
            "CHAPITRE XXI\n",
            "CHAPITRE XXIV\n",
            "CHAPITRE XXV\n",
            "CHAPITRE XXVI\n",
            "PREMIER CHAPITRE has 2583 words\n",
            "CHAPITRE II has 2380 words\n",
            "CHAPITRE III has 1345 words\n",
            "CHAPITRE IV has 3157 words\n",
            "CHAPITRE V has 3031 words\n",
            "CHAPITRE VII has 3060 words\n",
            "CHAPITRE VIII has 2128 words\n",
            "CHAPITRE IX has 1289 words\n",
            "CHAPITRE X has 4870 words\n",
            "CHAPITRE XI has 1128 words\n",
            "CHAPITRE XIII has 2552 words\n",
            "CHAPITRE XIV has 3041 words\n",
            "CHAPITRE XV has 3526 words\n",
            "CHAPITRE XVII has 1461 words\n",
            "CHAPITRE XXI has 5162 words\n",
            "CHAPITRE XXIV has 2231 words\n",
            "CHAPITRE XXV has 3054 words\n",
            "CHAPITRE XXVI has 5449 words\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: PREMIER CHAPITRE\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE II\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE III\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE IV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE V\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE VII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE VIII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE IX\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE X\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XI\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XIII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XIV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XVII\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXI\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXIV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXV\n",
            "CHAPTER DOES NOT NEED TO BE FILTERED: CHAPITRE XXVI\n",
            "\n",
            "CHAPTERS INCLUDED:\n",
            "PREMIER CHAPITRE\n",
            "CHAPITRE II\n",
            "CHAPITRE III\n",
            "CHAPITRE IV\n",
            "CHAPITRE V\n",
            "CHAPITRE VII\n",
            "CHAPITRE VIII\n",
            "CHAPITRE IX\n",
            "CHAPITRE X\n",
            "CHAPITRE XI\n",
            "CHAPITRE XIII\n",
            "CHAPITRE XIV\n",
            "CHAPITRE XV\n",
            "CHAPITRE XVII\n",
            "CHAPITRE XXI\n",
            "CHAPITRE XXIV\n",
            "CHAPITRE XXV\n",
            "CHAPITRE XXVI\n",
            "{'chapter_count': 18,\n",
            " 'filtered_chapter_count': 18,\n",
            " 'filtered_chapters_with_count': 'PREMIER CHAPITRE -- 2583 words\\n'\n",
            "                                 'CHAPITRE II -- 2380 words\\n'\n",
            "                                 'CHAPITRE III -- 1345 words\\n'\n",
            "                                 'CHAPITRE IV -- 3157 words\\n'\n",
            "                                 'CHAPITRE V -- 3031 words\\n'\n",
            "                                 'CHAPITRE VII -- 3060 words\\n'\n",
            "                                 'CHAPITRE VIII -- 2128 words\\n'\n",
            "                                 'CHAPITRE IX -- 1289 words\\n'\n",
            "                                 'CHAPITRE X -- 4870 words\\n'\n",
            "                                 'CHAPITRE XI -- 1128 words\\n'\n",
            "                                 'CHAPITRE XIII -- 2552 words\\n'\n",
            "                                 'CHAPITRE XIV -- 3041 words\\n'\n",
            "                                 'CHAPITRE XV -- 3526 words\\n'\n",
            "                                 'CHAPITRE XVII -- 1461 words\\n'\n",
            "                                 'CHAPITRE XXI -- 5162 words\\n'\n",
            "                                 'CHAPITRE XXIV -- 2231 words\\n'\n",
            "                                 'CHAPITRE XXV -- 3054 words\\n'\n",
            "                                 'CHAPITRE XXVI -- 5449 words\\n',\n",
            " 'filtered_total_word_count': 51447,\n",
            " 'number_of_excluded_chapters': 0,\n",
            " 'total_word_count': 51447}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and Download JSON\n",
        "# Click the download link that will appear after running this cell.\n",
        "try:\n",
        "    json_filename = f\"{isbn_ten}_chapters.json\"\n",
        "    with open(json_filename, 'w') as json_file:\n",
        "        json.dump(chapters_data, json_file, indent=4)\n",
        "\n",
        "    files.download(json_filename)  # Make sure 'files' is imported from google.colab\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error saving or downloading JSON: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "WIQN6rMj5iKV",
        "outputId": "feadd3a8-42d4-42b7-bd6e-e35599456bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_69fa5ee2-a290-4599-b4e4-3f96fb8cf439\", \"9354990517_chapters.json\", 146961)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZvB98JFOjuGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}