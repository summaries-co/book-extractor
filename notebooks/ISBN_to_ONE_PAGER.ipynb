{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU88K8HFjq7z"
      },
      "source": [
        "This notebook creates a **One-Pager Summary** from an ISBN using OpenAI's API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mJx7XA14jeh1"
      },
      "outputs": [],
      "source": [
        "#@markdown # Enter the required information for the summarization process.\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Step 1:** Enter API Key and ISBN\n",
        "\n",
        "open_api_key = '' #@param {type:\"string\"}\n",
        "isbn = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0ZlmW0_jvvG",
        "outputId": "70fdc662-5a77-4b01-cb79-4f64a6a30ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "import json\n",
        "import pprint\n",
        "from openai import OpenAI\n",
        "import time\n",
        "from google.colab import files\n",
        "import io\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "R49cgZtHj3-8"
      },
      "outputs": [],
      "source": [
        "def add_space_between_sentences(text):\n",
        "    save = []\n",
        "    for i,v in enumerate(text):\n",
        "        if v in ['.', '?', '!'] and i+1 < len(text) and text[i+1].isupper():\n",
        "            #text = text.replace(char, char + ' ')\n",
        "            save.append(i)\n",
        "\n",
        "    counter = 0\n",
        "    for i,v in enumerate(save):\n",
        "\n",
        "        if i == 0:\n",
        "            text = text[:v+1] + ' ' + text[v+1:]\n",
        "            counter += 1\n",
        "        else:\n",
        "            text = text[:v+counter+1] + ' ' + text[v+counter+1:]\n",
        "            counter += 1\n",
        "    return text\n",
        "\n",
        "def text_cleaner(summary):\n",
        "    # summary = summary.replace('\\t', '')\n",
        "    # summary = summary.replace('\\n', '')\n",
        "    if summary:\n",
        "        summary = \" \".join(summary.split())\n",
        "\n",
        "    return summary\n",
        "\n",
        "model = 'gpt-4-1106-preview'\n",
        "\n",
        "def prompt_model(text, model=model, open_api_key=open_api_key):\n",
        "    \"\"\"Send text to OpenAI model and return the response.\"\"\"\n",
        "    try:\n",
        "        start = time.time()\n",
        "        client = OpenAI(api_key=open_api_key)\n",
        "        print(\"Prompting model...\")\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": text}]\n",
        "        )\n",
        "        response = chat_completion.choices[0].message.content\n",
        "        print(\"Response received -- Time taken: {:.2f} seconds\".format(time.time() - start))\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to prompt model: {e}\")\n",
        "        raise\n",
        "\n",
        "def generate_one_pager(title, authors, metadata):\n",
        "    prompt = f\"Give me a long summary of {title} by {authors} given this metadata: {metadata}\"\n",
        "    result = prompt_model(prompt, model=model)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "def read_all_files_in_directory(directory):\n",
        "    files = os.listdir(directory)\n",
        "    return files\n",
        "\n",
        "def get_google_book_id(isbn):\n",
        "# Changed the API URL from a custom endpoint to the Google Books API:\n",
        "# Previous URL: 'https://book-summarizer-api-develop.up.railway.app/google_books_query/isbn:{isbn}'\n",
        "# New URL: 'https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}'\n",
        "# Reason for change:\n",
        "# The Google Books API is more reliable and widely supported, providing robust and direct access to extensive book data without the need for third-party services.\n",
        "    try:\n",
        "        url = f'https://www.googleapis.com/books/v1/volumes?q=isbn:{isbn}'\n",
        "        headers = {'accept': 'application/json'}\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            results = response.json()\n",
        "            if 'items' in results and results['items']:\n",
        "                google_book_id = results['items'][0]['id']\n",
        "                print(f\"Google Book ID {google_book_id} has been fetched for {isbn}.\")\n",
        "                return results['items'][0]['volumeInfo']\n",
        "            else:\n",
        "                print(\"No books found for the given ISBN.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(f\"Failed to fetch book details, status code: {response.status_code}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching book details: {e}\")\n",
        "        return None\n",
        "\n",
        "def prepare_one_pager(isbn):\n",
        "    google_book_metadata = get_google_book_id(isbn)\n",
        "    if google_book_metadata:\n",
        "        try:\n",
        "            one_pager = generate_one_pager(google_book_metadata['title'], google_book_metadata.get('authors', ['Unknown author']), google_book_metadata)\n",
        "            return one_pager\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to generate one pager: {e}\")\n",
        "            return \"Error in generating summary\"\n",
        "    else:\n",
        "        print(\"Metadata not found, cannot generate one pager.\")\n",
        "        return \"Metadata not found\"\n",
        "\n",
        "def write_to_file(file_name, text):\n",
        "    with open(file_name, 'w') as file:\n",
        "        file.write(text)\n",
        "    print(f\"File saved as {file_name}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Xyr-DFtVkIa9",
        "outputId": "a0da3f52-6007-4ae9-8c72-fc2eb6ed85e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Book ID OprNBAAAQBAJ has been fetched for 1626813582.\n",
            "Prompting model...\n",
            "Response received -- Time taken: 24.17 seconds\n",
            "\"Exponential Organizations\" by Salim Ismail, Yuri van Geest, and Mike Malone is a seminal work that examines the emerging business entities known as Exponential Organizations, or ExOs, that are reshaping the landscape of the corporate world through their unparalleled ability to grow and innovate at a pace far surpassing that of traditional companies.\n",
            "\n",
            "At the core of the book is the observation that certain organizations can achieve performances that are not just incrementally better but exponentially superiorâ€”often 10 times more effective than their peers. This radical advantage is largely credited to their aptness to harness cutting-edge technological assets and innovative organizational strategies.\n",
            "\n",
            "The authors argue that these Exponential Organizations thrive by employing a new organizational structure that is suitable for the modern, fast-paced, technologically-driven environment. They distinguish themselves by having attributes and a mindset that leverages five internal mechanisms (termed as IDEAS: Interfaces, Dashboards, Experimentation, Autonomy, and Social technologies) and five external elements (SCALE: Staff on demand, Community and crowd, Algorithms, Leveraged assets, and Engagement).\n",
            "\n",
            "ExOs like Airbnb, Uber, and Google are quintessential examples of businesses that do not abide by the traditional economies of scale but rather benefit from what the authors call the \"economies of information,\" which provide them with the agility to scale up rapidly without corresponding increases in their resource base.\n",
            "\n",
            "In \"Exponential Organizations,\" Salim Ismail not only describes the ten characteristics vital to the architecture and ethos of an ExO but also provides a pragmatic guide for existing businesses and startups to transform and adapt to this Exponential model. The book delves into various case studies and real-world examples, demonstrating how organizations can streamline their performance and grow beyond the limitations of a linear growth trajectory.\n",
            "\n",
            "The work is divided into multiple sections that take the reader step by step through understanding what ExOs are, why they are so disruptive, how they operate, and why they are considered to be the new norm for business success. It explores the interplay between rapidly advancing technologies and innovative management practices that enable these organizations to thrive in today's business ecosystem.\n",
            "\n",
            "To remain competitive, the authors emphatically propose that leaders, entrepreneurs, and corporations must reexamine their organizational designs and adopt a more expansive, flexible, and information-centric mindset that mirrors the Exponential Organizations. They must be willing to let go of outdated strategies and tap into the global brain, connect through technology, and propel their companies into a future where growth is exponential rather than linear.\n",
            "\n",
            "\"Exponential Organizations\" concludes with actionable insights and strategies for companies looking to make the transition into this new organizational paradigm, ensuring the book is not only a source of extraordinary insights but also a practical handbook for innovation and leadership in the 21st century's business environment.\n",
            "File saved as 1626813582_one_pager.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b47dec83-8240-4e76-969a-77689cd3cf8c\", \"1626813582_one_pager.txt\", 3192)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown **Step 3:** Generate One Pager Summary and Download\n",
        "\n",
        "#@markdown Ensure that the ISBN is correctly entered at the beginning of this notebook. Once verified, click the **\"Play\"** button on the left of this cell.\n",
        "\n",
        "one_pager_content = prepare_one_pager(isbn)\n",
        "\n",
        "output_filename = f'{isbn}_one_pager.txt'\n",
        "download_link = write_to_file(output_filename, one_pager_content)\n",
        "files.download(output_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}